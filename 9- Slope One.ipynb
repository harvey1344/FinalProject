{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The penultimate algorithm I will be testing is Slope One. Described as a simple\n",
    "but effective collaborative model. It is neither a nearest neirbough or a matirx factorisation algorithm and has no tunable parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from surprise import Dataset, SlopeOne\n",
    "from surprise.accuracy import rmse, mae\n",
    "from surprise.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#split into validate and test sets\n",
    "\n",
    "data100k = Dataset.load_builtin('ml-100k')\n",
    "raw_ratings= data100k.raw_ratings\n",
    "\n",
    "random.seed(2001)\n",
    "np.random.seed(2001)\n",
    "random.shuffle(raw_ratings)\n",
    "\n",
    "# create threshold for unseen, 80-20\n",
    "cutoff = int(0.8 * len(raw_ratings))\n",
    "A_raw= raw_ratings[:cutoff]\n",
    "B_raw= raw_ratings[cutoff:]\n",
    "\n",
    "# data is now only set A ratings\n",
    "data100k.raw_ratings= A_raw"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased accuracy on 100k=, RMSE: 0.9438\n",
      "Fit time for 100k = 0.8432004451751709\n",
      "Test time for 100k =2.370535373687744\n"
     ]
    }
   ],
   "source": [
    "# training and testing on ml100k\n",
    "algo= SlopeOne()\n",
    "\n",
    "trainset = data100k.build_full_trainset()\n",
    "start_fit = time.time()\n",
    "algo.fit(trainset)\n",
    "fit_100k= time.time()-start_fit\n",
    "\n",
    "testset = data100k.construct_testset(B_raw)  # testset is now the set B\n",
    "start_predict= time.time()\n",
    "predictions_100k = algo.test(testset)\n",
    "test_100k= time.time()-start_predict\n",
    "print(\"Unbiased accuracy on 100k=,\", end=\" \")\n",
    "rmse_100k= rmse(predictions_100k)\n",
    "print(\"Fit time for 100k = \"+ str(fit_100k))\n",
    "print(\"Test time for 100k =\"+ str(test_100k))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased accuracy on 1m=, RMSE: 0.9065\n",
      "Fit time for 1m = 13.68208909034729\n",
      "Test time for 1m =54.40141558647156\n"
     ]
    }
   ],
   "source": [
    "# training and testing on ml1m\n",
    "data1m= Dataset.load_builtin('ml-1m')\n",
    "trainset, testset = train_test_split(data1m, test_size=0.25, random_state=1)\n",
    "start_fit = time.time()\n",
    "algo.fit(trainset)\n",
    "fit_1m= time.time()-start_fit\n",
    "\n",
    "start_predict= time.time()\n",
    "predictions_1m = algo.test(testset)\n",
    "test_1m= time.time()-start_predict\n",
    "print(\"Unbiased accuracy on 1m=,\", end=\" \")\n",
    "rmse_1m= rmse(predictions_1m)\n",
    "print(\"Fit time for 1m = \"+ str(fit_1m))\n",
    "print(\"Test time for 1m =\"+ str(test_1m))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "data_100k=pd.DataFrame(data={'Algorithm':['Slope One'],\n",
    "                        'RMSE': [rmse_100k],\n",
    "                        'Fit Time': [fit_100k],\n",
    "                        'Predict Time': [test_100k]})\n",
    "data_1m=pd.DataFrame(data={'Algorithm':['Slope One'],\n",
    "                        'RMSE': [rmse_1m],\n",
    "                        'Fit Time': [fit_1m],\n",
    "                        'Predict Time': [test_1m]})\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "data_100k.to_csv('./algo_data/slope_one_100k')\n",
    "data_1m.to_csv('./algo_data/slope_one_1m')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from own_algorithms.top_n_list import get_top_n_list\n",
    "\n",
    "movies_cols = ['movie_id', 'title', 'genres']\n",
    "movies_df = pd.read_csv('./ml-1m/movies.dat', sep='::', names=movies_cols, engine='python', encoding='latin-1')\n",
    "\n",
    "# create top n list\n",
    "movies_398=get_top_n_list(predictions_1m, 10, '398', movies_df)\n",
    "movies_1=get_top_n_list(predictions_1m, 10, '1', movies_df)\n",
    "movies_134=get_top_n_list(predictions_1m, 10, '134', movies_df)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "['Braveheart (1995)',\n 'In the Line of Fire (1993)',\n 'Last of the Mohicans, The (1992)',\n 'Austin Powers: International Man of Mystery (1997)',\n 'Full Monty, The (1997)',\n 'Office Space (1999)',\n 'Being John Malkovich (1999)',\n 'Toy Story 2 (1999)',\n 'Chicken Run (2000)',\n 'Almost Famous (2000)']"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_134"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# load the current prediction tables and add this column\n",
    "df398 = pd.read_csv('./predictions/398.csv')\n",
    "df1= pd.read_csv('./predictions/1.csv')\n",
    "df134= pd.read_csv('./predictions/134.csv')\n",
    "df398['Slope One']= movies_398\n",
    "df1['Slope One']= movies_1\n",
    "df134['Slope One']= movies_134"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "#save predictions with slope one\n",
    "df398.to_csv('./predictions/398.csv', index=False)\n",
    "df1.to_csv('./predictions/1.csv', index=False)\n",
    "df134.to_csv('./predictions/134.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
